<!DOCTYPE html>
<style>
width: 100%;
height: 120px;
margin-top: 10px;
}
.image-placeholder {
border: 1px dashed #999;
padding: 20px;
text-align: center;
color: #666;
margin: 10px 0;
}
</style>
</head>
<body>
<h1>CS180 Project 2: Fun with Filters and Frequencies</h1>


<div class="section">
<h2>Part 1: Filters and Edges</h2>


<h3>1.1 Convolution</h3>
<div class="image-placeholder">Add images/results here</div>
<p> The runtime is nearly identical for greyscale images between my convolution and scipy's .convolve2d, although mine
  is slightly slower with color images. To deal with padding boundaries I initially cropped but realized I was losing information,
  so I ended up reflecting the boundaries like scipy did. I implemented my convolution with four for loops, and then two, saving time
  by multiplying patches of the image by the kernel instead of going element by element. I implemented padding with zeroes. I ran my two
  loop convolution against scipy's convolution on an image of me in grayscale using: a box filter, a Dx filter, and a Dy filter.
  Here is my code for this section:</p>
<pre><code class="language-python">def four_for_convolution(input_image, filter_type="box_filter", kernel_size=9):
    if filter_type == "box_filter":
        kernel_values = np.full((kernel_size, kernel_size), 1/(kernel_size*kernel_size))
        kernel_array = np.flip(kernel_values)
        pad_h = kernel_size // 2
        pad_w = kernel_size // 2
    if filter_type == "dx":
        kernel_values = np.array([[-1, 0, 1]])
        kernel_array = np.flip(kernel_values)
        pad_h = 1
        pad_w = 0
    if filter_type == "dy":
        kernel_values = np.array([[-1], [0], [1]])
        kernel_array = np.flip(kernel_values)
        pad_h = 0
        pad_w = 1
    input_width = input_image.shape[1]
    input_height = input_image.shape[0]
    output_image = np.empty((input_height, input_width))

    # Pad the image with zeros
    padded_image = np.pad(input_image, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant', constant_values=0)

    for y in np.arange(input_height):
        for x in np.arange(input_width):
            current_pixel = input_image[y,x] # 0,0 is top left, max,max is bottom right
            #now do the kernel convolution
            sum = 0
            for j in np.arange(kernel_array.shape[1]):
                for i in np.arange(kernel_array.shape[0]):
                        # checks the bounds of x and y of current pixel
                        hy = y + j
                        hx = x + i
                        sum += kernel_array[j, i] * padded_image[hy, hx]
            output_image[y,x] = sum
    return output_image

#two four loops convolution
def two_for_convolution(input_image, filter_type="box_filter", kernel_size=9):
    if filter_type == "box_filter":
        kernel_values = np.full((kernel_size, kernel_size), 1/(kernel_size*kernel_size))
        kernel_array = np.flip(kernel_values)
        pad_h = kernel_size // 2
        pad_w = kernel_size // 2
    if filter_type == "dx":
        kernel_array = np.array([[-1, 0, 1]])
        pad_h = 0
        pad_w = 1
    if filter_type == "dy":
        kernel_array = np.array([[-1], [0], [1]])
        pad_h = 1
        pad_w = 0
    input_width = input_image.shape[1]
    input_height = input_image.shape[0]
    output_image = np.empty((input_height, input_width))

    # Pad the image with zeros
    padded_image = np.pad(input_image, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant', constant_values=0)

    for y in np.arange(input_height):
        for x in np.arange(input_width):
            #remember this is y and x of the padded image not the input image
            #it takes a subsection with padded zeroes if out of bounds
            image_subsection = padded_image[y:y + kernel_array.shape[0], x:x+kernel_array.shape[1]]
            # * is element wise multiplication @ is the matrix multiplcation
            # just need to check out of bounds
            #multiply arrays not pixels for each iteration of the loop
            output_image[y][x] = np.sum(image_subsection * kernel_array)
    output_image = crop_convolution(output_image, pad_h, pad_w)
    return output_image

#convolution calling scipy
def scipy_convolution(input_image, filter_type="box_filter", kernel_size=9, sigma=5):
    if filter_type == "box_filter":
        kernel_array = np.flip(np.full((kernel_size, kernel_size), 1/(kernel_size*kernel_size)))
    if filter_type == "dx":
        kernel_array = np.flip(np.array([[-1, 0, 1]]))
    if filter_type == "dy":
        kernel_array = np.flip(np.array([[-1], [0], [1]]))
    if filter_type == "gaussian":
        g_1d = cv2.getGaussianKernel((6*sigma) + 1, sigma)
        g_2d = np.outer(g_1d, g_1d)
        kernel_array = np.flip(g_2d)
    if filter_type == "DoG x":
        kernel_array = np.flip(DoG_filter("x"))
    if filter_type == "DoG y":
        kernel_array = np.flip(DoG_filter("y"))
    return scipy.signal.convolve2d(input_image, kernel_array, mode='same', boundary='symm')
</code></pre>

<h3>1.2 Partial Derivatives and Edges</h3>
<div class="image-placeholder">Add images/results here</div>
<p> I used the scipy.convolve2d function for all further parts. I calculated the partial derivatives in x and y
    for the cameraman image vy convolving the image with finite difference operators D_x and D_y. I calculated a gradient magnitude image by taking the Dx image and Dy image and calculating
  the sqrt of square(Dx) + square(Dy). This only displays the edges of the images, both images on the x plane and the y plane. However,
  without binarizing the edges, the gradient magnitude image looks very noisy To fix this, we suppress the noise while retaining edges
  by setting all pixels to either a 0 (black) or 1 (white) depending on if the pixel's grayscale value is larger than a certain threshold. For 
  my threshold I choose 60 as it retained most of the cameraman's detail while reducing the visible noise on the ground. Although I did
  find threshold 20 to be more aesthetically pleasing with the snow-like noise texture, even if it did have too much detail for the cameraman. 
</p>
<pre><code>
  def gradient_magnitude_image(input_image):
    dx = scipy_convolution(input_image, filter_type="dx")
    dy = scipy_convolution(input_image, filter_type="dy")
    return np.sqrt(np.square(dx) + np.square(dy))

  def binarize_gradient_magnitude(input_image, threshold=60):
      input_image = (input_image * 255).astype(np.uint8)
      return (input_image > threshold)
</code></pre>
  
<h3>1.3 Gaussian & DoG Filters</h3>
<div class="image-placeholder">Add images/results here</div>
<p>Even so, with just the difference operators Dx and Dy, the image contained a lot of noise that even binarizing the image
couldn't fix. To fix this I blurred the image using a gaussian kernel, and then repeated the procedure in the previous part. 
This got rid of almost all noise and made edges thicker and seemingly brighter. To make this faster I implemented DoG or
derivate of gaussian filters which looks the same but convolves the gaussian kernel with D_x and D_y before convolving with the image, 
which saves one convolution in total.</p>
<pre><code>
  def DoG_filter(type, sigma=2):
    g_size = 6 * sigma + 1
    g_1d = cv2.getGaussianKernel(g_size, sigma)
    g_2d = np.outer(g_1d, g_1d)
    input_image = np.flip(g_2d)
    if type == "x":
        DoG = scipy_convolution(input_image, "dx")
    if type == "y":
        DoG = scipy_convolution(input_image, "dy")
    return DoG

  def gradient_magnitude_image_DoG(input_image):
      dxog = scipy_convolution(input_image, filter_type="DoG x")
      dyog = scipy_convolution(input_image, filter_type="DoG y")
      return np.sqrt(np.square(dxog) + np.square(dyog))
</code></pre>

<div class="section">
<h2>Part 2: Applications</h2>


<h3>2.1 Unsharp Mask</h3>
<div class="image-placeholder">Add images/results here</div>
<textarea placeholder="Write your answer here..."></textarea>


<h3>2.2 Hybrid Images</h3>
<div class="image-placeholder">Add images/results here</div>
<textarea placeholder="Write your answer here..."></textarea>


<h3>Bells & Whistles: Hybrid Variations</h3>
<div class="image-placeholder">Add images/results here</div>
<textarea placeholder="Write your answer here..."></textarea>


<h3>2.3 + 2.4 Image Blending (Oraple)</h3>
<div class="image-placeholder">Add images/results here</div>
<textarea placeholder="Write your answer here..."></textarea>


<h3>Bells & Whistles: Custom Blends</h3>
<div class="image-placeholder">Add images/results here</div>
<textarea placeholder="Write your answer here..."></textarea>
</div>
</body>
</html>




